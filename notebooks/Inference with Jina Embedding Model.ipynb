{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interfere Jina Embedding Model Package from AWS Marketplace\n",
    "\n",
    "This notebook shows you how to deploy [jina-embedding-model](link) using Amazon SageMaker\n",
    "\n",
    "## Pre-requisites:\n",
    "1. **Note**: This notebook contains elements which render correctly in Jupyter interface. Open this notebook from an Amazon SageMaker Notebook Instance or Amazon SageMaker Studio.\n",
    "1. Ensure that IAM role used has **AmazonSageMakerFullAccess**\n",
    "1. To deploy this ML model successfully, ensure that:\n",
    "    1. Either your IAM role has these three permissions and you have authority to make AWS Marketplace subscriptions in the AWS account used: \n",
    "        1. **aws-marketplace:ViewSubscriptions**\n",
    "        1. **aws-marketplace:Unsubscribe**\n",
    "        1. **aws-marketplace:Subscribe**  \n",
    "    2. or your AWS account has a subscription to [jina-embedding-model](link). If so, skip step: [Subscribe to the model package](#1.-Subscribe-to-the-model-package)\n",
    "\n",
    "## Contents:\n",
    "1. [Subscribe to the model package](#1.-Subscribe-to-the-model-package)\n",
    "2. [Real-time inference](#2.-Real-time-inference)\n",
    "   1. [Create an endpoint with static instances](#A.-Create-an-endpoint-with-static-instances)\n",
    "   2. [Create an endpoint that automatically scales](#B.-Create-an-endpoint-that-automatically-scales)\n",
    "   3. [Create an serverless endpoint](#C.-Create-an-serverless-endpoint)\n",
    "   4. [Perform real-time inference](#C.-Perform-real-time-inference)\n",
    "   5. [Delete the endpoint](#H.-Delete-the-endpoint)\n",
    "3. [Batch inference](#3.-Batch-inference)\n",
    "4. [Clean-up](#4.-Clean-up)\n",
    "    1. [Delete the model](#A.-Delete-the-model)\n",
    "    2. [Unsubscribe to the listing (optional)](#B.-Unsubscribe-to-the-listing-(optional))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Subscribe to the model package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Real-time inference\n",
    "\n",
    "To learn about real-time inference capabilities in Amazon SageMaker, please refer to [Documentations](https://docs.aws.amazon.com/sagemaker/latest/dg/realtime-endpoints.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Create an endpoint with static instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "co = Client(region_name=region)\n",
    "co.create_endpoint(arn=model_package_arn, endpoint_name=\"my_endpoint\", instance_type=\"ml.m5.xlarge\", n_instances=1)\n",
    "\n",
    "# If the endpoint is already created, you just need to connect to it\n",
    "# co.connect_to_endpoint(endpoint_name=\"my_endpoint\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Create an endpoint that automatically scales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "co = Client(region_name=region)\n",
    "co.create_endpoint(arn=model_package_arn, endpoint_name=\"my_autoscaling_endpoint\", instance_type=\"ml.m5.xlarge\", n_instances=2)\n",
    "\n",
    "# If the endpoint is already created, you just need to connect to it\n",
    "# co.connect_to_endpoint(endpoint_name=\"my_autoscaling_endpoint\")\n",
    "\n",
    "co.register_scaling(max_capacity=5, min_capacity=2)\n",
    "\n",
    "r = co.set_step_autoscaling(\n",
    "    policy_name=\"down\",\n",
    "    policy_configuration={\n",
    "        \"AdjustmentType\": \"ExactCapacity\",\n",
    "        \"StepAdjustments\": [\n",
    "            {\n",
    "                \"MetricIntervalUpperBound\": 0,\n",
    "                \"ScalingAdjustment\": 2,\n",
    "            }\n",
    "        ],\n",
    "        \"MetricAggregationType\": \"Average\",\n",
    "        \"Cooldown\": 10,\n",
    "    },\n",
    ")\n",
    "down_policy = r['PolicyARN']\n",
    "\n",
    "r = co.set_step_autoscaling(\n",
    "    policy_name=\"up\",\n",
    "    policy_configuration={\n",
    "        \"AdjustmentType\": \"ChangeInCapacity\",\n",
    "        \"StepAdjustments\": [\n",
    "            {\n",
    "                \"MetricIntervalLowerBound\": 0,\n",
    "                \"MetricIntervalUpperBound\": 10,\n",
    "                \"ScalingAdjustment\": 0,\n",
    "            },\n",
    "            {\n",
    "                \"MetricIntervalLowerBound\": 10,\n",
    "                \"MetricIntervalUpperBound\": 40,\n",
    "                \"ScalingAdjustment\": 3,\n",
    "            },\n",
    "            {\n",
    "                \"MetricIntervalLowerBound\": 40,\n",
    "                \"ScalingAdjustment\": 4,\n",
    "            },\n",
    "        ],\n",
    "        \"MetricAggregationType\": \"Average\",\n",
    "        \"Cooldown\": 10,\n",
    "    },\n",
    ")\n",
    "up_policy = r['PolicyARN']\n",
    "\n",
    "co.set_metric_alarm(policy_arn=down_policy, \n",
    "    AlarmName=f\"step_scaling_policy_alarm_down\",\n",
    "    MetricName=\"CPUUtilization\",\n",
    "    Namespace=\"/aws/sagemaker/Endpoints\",\n",
    "    Statistic=\"Average\",\n",
    "    EvaluationPeriods=1,\n",
    "    DatapointsToAlarm=1,\n",
    "    Threshold=30,\n",
    "    ComparisonOperator=\"LessThanOrEqualToThreshold\",\n",
    "    TreatMissingData=\"missing\",\n",
    "    Period=60,\n",
    "    Unit=\"Percent\",\n",
    ")\n",
    "\n",
    "co.set_metric_alarm(policy_arn=up_policy,\n",
    "    AlarmName=f\"step_scaling_policy_alarm_up\",\n",
    "    MetricName=\"CPUUtilization\",\n",
    "    Namespace=\"/aws/sagemaker/Endpoints\",\n",
    "    Statistic=\"Average\",\n",
    "    EvaluationPeriods=1,\n",
    "    DatapointsToAlarm=1,\n",
    "    Threshold=60,\n",
    "    ComparisonOperator=\"GreaterThanThreshold\",\n",
    "    TreatMissingData=\"missing\",\n",
    "    Period=10,\n",
    "    Unit=\"Percent\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C. Create an serverless endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.serverless import ServerlessInferenceConfig\n",
    "\n",
    "\n",
    "sls_config = ServerlessInferenceConfig(\n",
    "    memory_size_in_mb=6144,\n",
    "    max_concurrency=20,\n",
    "    provisioned_concurrency=10\n",
    ")\n",
    "\n",
    "co.create_endpoint(arn=model_package_arn, role=role, endpoint_name=\"my_sls_endpoint\", sls_config=sls_config)\n",
    "\n",
    "# If the endpoint is already created, you just need to connect to it\n",
    "# co.connect_to_endpoint(endpoint_name=\"my_sls_endpoint\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Batch inference\n",
    "\n",
    "To learn about batch transform capabilities in Amazon SageMaker, please refer to [Documentations](https://docs.aws.amazon.com/sagemaker/latest/dg/batch-transform.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "co.create_transform_job(\n",
    "    arn=model_package_arn,\n",
    "    n_instances=1,\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "    input_path=\"s3://path/to/input/data\",\n",
    "    output_path=\"s3://path/to/output\",\n",
    "    content_type=\"application/csv\",\n",
    "    split_type=\"Line\",\n",
    "    strategy=\"MultiRecord\",\n",
    "    role=role\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Clean-up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Delete the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "co.delete_endpoint()\n",
    "co.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Unsubscribe to the listing (optional)\n",
    "\n",
    "If you would like to unsubscribe to the model package, follow these steps. Before you cancel the subscription, ensure that you do not have any [deployable model](https://console.aws.amazon.com/sagemaker/home#/models) created from the model package or using the algorithm. Note - You can find this information by looking at the container name associated with the model. \n",
    "\n",
    "**Steps to unsubscribe to product from AWS Marketplace**:\n",
    "1. Navigate to __Machine Learning__ tab on [__Your Software subscriptions page__](https://aws.amazon.com/marketplace/ai/library?productType=ml&ref_=mlmp_gitdemo_indust)\n",
    "2. Locate the listing that you want to cancel the subscription for, and then choose __Cancel Subscription__  to cancel the subscription.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
