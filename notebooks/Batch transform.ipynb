{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embed large text files using Batch Transform\n",
    "\n",
    "If you have extensive text datasets that need embeddings using Jina's models, Amazon SageMaker's Batch Transform is a handy tool. Instead of processing text one-by-one, Batch Transform allows for bulk processing. Simply provide the path to your dataset in an S3 bucket and specify an output path. Once the transform job is completed, the embeddings will be uploaded to the designated S3 location."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-requisites:\n",
    "1. Ensure that IAM role used has **AmazonSageMakerFullAccess**\n",
    "1. To deploy this ML model successfully, ensure that:\n",
    "    1. Either your IAM role has these three permissions and you have authority to make AWS Marketplace subscriptions in the AWS account used: \n",
    "        1. **aws-marketplace:ViewSubscriptions**\n",
    "        1. **aws-marketplace:Unsubscribe**\n",
    "        1. **aws-marketplace:Subscribe**  \n",
    "    2. or your AWS account has a subscription to [jina-embedding-model](link).\n",
    "\n",
    "# Model package setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install `jina-sagemaker` package \n",
    "\n",
    "\n",
    "```bash\n",
    "pip install --upgrade jina-sagemaker\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the role as required by SageMaker\n",
    "role = \"...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "\n",
    "# Specify the model name\n",
    "model_name = \"jina-embeddings-v2-small-en\"\n",
    "\n",
    "# Mapping for Model Packages\n",
    "model_package_map = {\n",
    "    'ap-northeast-1': f'arn:aws:sagemaker:ap-northeast-1:253352124568:model-package/{model_name}',\n",
    "    'ap-northeast-2': f'arn:aws:sagemaker:ap-northeast-2:253352124568:model-package/{model_name}',\n",
    "    'ap-south-1': f'arn:aws:sagemaker:ap-south-1:253352124568:model-package/{model_name}',\n",
    "    'ap-southeast-1': f'arn:aws:sagemaker:ap-southeast-1:253352124568:model-package/{model_name}',\n",
    "    'ap-southeast-2': f'arn:aws:sagemaker:ap-southeast-2:253352124568:model-package/{model_name}',\n",
    "    'ca-central-1': f'arn:aws:sagemaker:ca-central-1:253352124568:model-package/{model_name}',\n",
    "    'eu-central-1': f'arn:aws:sagemaker:eu-central-1:253352124568:model-package/{model_name}',\n",
    "    'eu-north-1': f'arn:aws:sagemaker:eu-north-1:253352124568:model-package/{model_name}',\n",
    "    'eu-west-1': f'arn:aws:sagemaker:eu-west-1:253352124568:model-package/{model_name}',\n",
    "    'eu-west-2': f'arn:aws:sagemaker:eu-west-2:253352124568:model-package/{model_name}',\n",
    "    'eu-west-3': f'arn:aws:sagemaker:eu-west-3:253352124568:model-package/{model_name}',\n",
    "    'sa-east-1': f'arn:aws:sagemaker:sa-east-1:253352124568:model-package/{model_name}',\n",
    "    'us-east-1': f'arn:aws:sagemaker:us-east-1:253352124568:model-package/{model_name}',\n",
    "    'us-east-2': f'arn:aws:sagemaker:us-east-2:253352124568:model-package/{model_name}',\n",
    "    'us-west-1': f'arn:aws:sagemaker:us-west-1:253352124568:model-package/{model_name}',\n",
    "    'us-west-2': f'arn:aws:sagemaker:us-west-2:253352124568:model-package/{model_name}'\n",
    "}\n",
    "\n",
    "# Specify the model you want to use\n",
    "if region not in model_package_map.keys():\n",
    "    raise Exception(f\"Current boto3 session region {region} is not supported.\")\n",
    "\n",
    "model_package_arn = model_package_map[region]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the batch transform job\n",
    "\n",
    "### Gotchas\n",
    "\n",
    "##### Input File\n",
    "\n",
    "Input file should be a CSV file either on S3 or locally. The CSV file should have the following properties:\n",
    "\n",
    "- **No Headers**: should not include a header row.\n",
    "- **CSV Quoting**: the text shouldn't contain surrounding quotes.\n",
    "- **Escape Characters**: escape character (`\\`) is used to prevent special characters from being interpreted as part of the CSV formatting.\n",
    "- **Column(s)**: If on S3, it must have two columns: ID and text to be embedded. If local, only the text column is required. The client will dynamically generate the document IDs as needed.\n",
    "\n",
    "\n",
    "##### Output File\n",
    "\n",
    "The output file will be a jsonlines file with extension `.out`. Each line will contain a list of documents IDs and their embeddings. The output file will be downloaded to the `output_path` if it is a local path. If it is an S3 path, the output file will be uploaded to the S3 bucket.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's download a sample dataset & store as a CSV in the expected format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_imdb_dataset(path: str, N: int = 100):\n",
    "    import csv\n",
    "    from datasets import load_dataset\n",
    "\n",
    "    dataset = load_dataset('imdb', split='train')\n",
    "    dataset.to_pandas().text.head(N).to_csv(\n",
    "        path, \n",
    "        header=False, # no header\n",
    "        index=False,\n",
    "        quoting=csv.QUOTE_NONE, # no quotes\n",
    "        escapechar='\\\\' # \\ is the escape character\n",
    "    )\n",
    "\n",
    "# Save the dataset\n",
    "save_imdb_dataset('imdb.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jina_sagemaker import Client\n",
    "\n",
    "client = Client(region_name=region)\n",
    "\n",
    "input_path = 'imdb.csv' # local path to the dataset downloaded above\n",
    "output_path = 'output_dir' # local path to the output directory\n",
    "\n",
    "# Create a batch transform job with the model package\n",
    "client.create_transform_job(\n",
    "    arn=model_package_arn,\n",
    "    role=role,\n",
    "    n_instances=1,\n",
    "    instance_type=\"ml.g4dn.xlarge\",\n",
    "    input_path=input_path,\n",
    "    output_path=output_path,\n",
    "    logs=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depending on the size of your dataset, this may take a few minutes. The output file will be stored on S3 and downloaded to the `output_path` directory."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
