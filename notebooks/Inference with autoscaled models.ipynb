{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference with Autoscaled Models\n",
    "\n",
    "If [statically provisioned instances](./Real-time%20inference.ipynb) don't meet your needs, Amazon SageMaker offers automatic scaling for your hosted models. This allows the number of instances allocated for a model to dynamically adjust based on traffic demand, ensuring your deployment is both cost-effective and adept at managing varying traffic loads."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Subscribe to the model package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade jina-sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jina_sagemaker import Client\n",
    "import boto3\n",
    "\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "# Specify the role if needed\n",
    "role = \"\"\n",
    "role = 'arn:aws:iam::253352124568:role/service-role/AmazonSageMaker-ExecutionRole-20230527T104084'\n",
    "\n",
    "# Specify the model name\n",
    "model_name = \"jina-embedding-l-en-v1\"\n",
    "\n",
    "# Mapping for Model Packages\n",
    "model_package_map = {\n",
    "    \"us-east-1\": f\"arn:aws:sagemaker:us-east-1:253352124568:model-package/{model_name}\",\n",
    "}\n",
    "\n",
    "# Specify the model you want to use\n",
    "if region not in model_package_map.keys():\n",
    "    raise Exception(f\"Current boto3 session region {region} is not supported.\")\n",
    "\n",
    "model_package_arn = model_package_map[region]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Create an endpoint that automatically scales\n",
    "\n",
    "In this section, we configure an autoscaling endpoint that leverages step scaling, which scales a resource based on a set of scaling adjustments that vary based on the size of the alarm breach. For an in-depth understanding of step scaling, you can refer to the [Documentations](https://docs.aws.amazon.com/autoscaling/application/userguide/application-auto-scaling-step-scaling-policies.html).\n",
    "\n",
    "When utilizing step scaling, it's your responsibility to configure the alarms that trigger the policy. Generally, you'll want to establish two alarms: one for triggering a step scale-in action and another for initiating a step scale-out action. Note that the upper and lower bounds specified in these policies are relative to the thresholds set in the corresponding alarms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "client = Client(region_name=region)\n",
    "client.create_endpoint(arn=model_package_arn, role=role, endpoint_name=\"my-autoscaling-endpoint\", instance_type=\"ml.g4dn.xlarge\", n_instances=2)\n",
    "\n",
    "# If the endpoint is already created, you just need to connect to it\n",
    "# co.connect_to_endpoint(endpoint_name=\"my-autoscaling_endpoint\")\n",
    "\n",
    "client.register_scalable_target(max_capacity=5, min_capacity=2)\n",
    "\n",
    "r = client.set_step_autoscaling(\n",
    "    policy_name=\"down\",\n",
    "    policy_configuration={\n",
    "        \"AdjustmentType\": \"ExactCapacity\",\n",
    "        \"StepAdjustments\": [\n",
    "            {\n",
    "                \"MetricIntervalUpperBound\": 0,\n",
    "                \"ScalingAdjustment\": 2,\n",
    "            }\n",
    "        ],\n",
    "        \"MetricAggregationType\": \"Average\",\n",
    "        \"Cooldown\": 10,\n",
    "    },\n",
    ")\n",
    "down_policy = r['PolicyARN']\n",
    "\n",
    "r = client.set_step_autoscaling(\n",
    "    policy_name=\"up\",\n",
    "    policy_configuration={\n",
    "        \"AdjustmentType\": \"ChangeInCapacity\",\n",
    "        \"StepAdjustments\": [\n",
    "            {\n",
    "                \"MetricIntervalLowerBound\": 0,\n",
    "                \"MetricIntervalUpperBound\": 10,\n",
    "                \"ScalingAdjustment\": 0,\n",
    "            },\n",
    "            {\n",
    "                \"MetricIntervalLowerBound\": 10,\n",
    "                \"MetricIntervalUpperBound\": 40,\n",
    "                \"ScalingAdjustment\": 3,\n",
    "            },\n",
    "            {\n",
    "                \"MetricIntervalLowerBound\": 40,\n",
    "                \"ScalingAdjustment\": 4,\n",
    "            },\n",
    "        ],\n",
    "        \"MetricAggregationType\": \"Average\",\n",
    "        \"Cooldown\": 10,\n",
    "    },\n",
    ")\n",
    "up_policy = r['PolicyARN']\n",
    "\n",
    "client.set_metric_alarm(policy_arn=down_policy, \n",
    "    AlarmName=f\"step_scaling_policy_alarm_down\",\n",
    "    MetricName=\"CPUUtilization\",\n",
    "    Namespace=\"/aws/sagemaker/Endpoints\",\n",
    "    Statistic=\"Average\",\n",
    "    EvaluationPeriods=1,\n",
    "    DatapointsToAlarm=1,\n",
    "    Threshold=30,\n",
    "    ComparisonOperator=\"LessThanOrEqualToThreshold\",\n",
    "    TreatMissingData=\"missing\",\n",
    "    Period=60,\n",
    "    Unit=\"Percent\",\n",
    ")\n",
    "\n",
    "client.set_metric_alarm(policy_arn=up_policy,\n",
    "    AlarmName=f\"step_scaling_policy_alarm_up\",\n",
    "    MetricName=\"CPUUtilization\",\n",
    "    Namespace=\"/aws/sagemaker/Endpoints\",\n",
    "    Statistic=\"Average\",\n",
    "    EvaluationPeriods=1,\n",
    "    DatapointsToAlarm=1,\n",
    "    Threshold=60,\n",
    "    ComparisonOperator=\"GreaterThanThreshold\",\n",
    "    TreatMissingData=\"missing\",\n",
    "    Period=10,\n",
    "    Unit=\"Percent\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Perform real-time inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = client.embed(texts=[\n",
    "    \"how is the weather today\", \n",
    "    \"what is the weather like today\",\n",
    "    \"what's the color of an orange\",\n",
    "])\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Clean-up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Delete the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.delete_endpoint()\n",
    "client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Unsubscribe to the listing (optional)\n",
    "\n",
    "If you would like to unsubscribe to the model package, follow these steps. Before you cancel the subscription, ensure that you do not have any [deployable model](https://console.aws.amazon.com/sagemaker/home#/models) created from the model package or using the algorithm. Note - You can find this information by looking at the container name associated with the model. \n",
    "\n",
    "**Steps to unsubscribe to product from AWS Marketplace**:\n",
    "1. Navigate to __Machine Learning__ tab on [__Your Software subscriptions page__](https://aws.amazon.com/marketplace/ai/library?productType=ml&ref_=mlmp_gitdemo_indust)\n",
    "2. Locate the listing that you want to cancel the subscription for, and then choose __Cancel Subscription__  to cancel the subscription.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
